{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process WRF DATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "#path to regional wrf data that you want to subset from\n",
    "#wrf_data = '/glade/scratch/adamhb/met_data/wrf_9km_1982_2020/'\n",
    "wrf_data = '/glade/work/xiugao/fates-input/ca-wrf-grassland/CLM1PT_data'\n",
    "\n",
    "#2.\n",
    "#output path where you want the subsetted, pre-processed data to go\n",
    "output_path = '/glade/scratch/adamhb/my_subset_data/stan_wrf_1950_2020/CLM1PT_data'\n",
    "\n",
    "#3.\n",
    "#Coordinates of site where you want to subset data\n",
    "\n",
    "#CZ2: 37.0311,-119.256599\n",
    "#STAN: 38.177648,-119.978692\n",
    "\n",
    "target_wrf_lat = 38.177648\n",
    "target_wrf_lon = -119.978692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User should not need to change anything after this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molar mass of water vapour [kg/mol]\n",
    "mm_h2o  = 0.01801505\n",
    "# Molar mass of dry air [kg/mol]\n",
    "mm_dry  = 0.02897\n",
    "# Molar mass ratio\n",
    "eps_mol = mm_h2o / mm_dry\n",
    "# Saturation vapour pressure at 273.15K [Pa]\n",
    "esat_0C = 611.65685464\n",
    "frac_2_pc = 100\n",
    "degC_2_K  = 273.15\n",
    "\n",
    "site_refhgt=2\n",
    "\n",
    "# Convert the user-defined target lon to be non-negative in the western hemisphere.\n",
    "# This is to match clm format\n",
    "target_lat = target_wrf_lat\n",
    "\n",
    "if target_wrf_lon < 0:\n",
    "    target_lon = target_wrf_lon + 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WRF LAT and LON indices at the closest WRF point to the target site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_func(a,b):\n",
    "    return math.sqrt(a**2 + b**2)\n",
    "\n",
    "def getDiff(d,var,target,r,c):\n",
    "    return abs(d[var][r,c].values - target)\n",
    "\n",
    "def getClosestWRFPoint(xds,lat_target,lon_target):\n",
    "\n",
    "    output = {'lat':[],'lon':[],'dist':[]}\n",
    "    for r in range(xds.LATIXY.shape[0]):\n",
    "        for c in range(xds.LATIXY.shape[1]):\n",
    "\n",
    "            lon_diff = getDiff(xds,'LONGXY',lon_target,r,c)\n",
    "            lat_diff = getDiff(xds,'LATIXY',lat_target,r,c)\n",
    "            dist = dist_func(lon_diff, lat_diff)\n",
    "            output['lat'].append(r)\n",
    "            output['lon'].append(c)\n",
    "            output['dist'].append(dist)\n",
    "            \n",
    "    output = pd.DataFrame(output)\n",
    "    closest = output.loc[output.dist == output.dist.min()]\n",
    "    lat_index = closest.lat.values\n",
    "    lon_index = closest.lon.values\n",
    "    return lat_index[0], lon_index[0]\n",
    "\n",
    "def get_last_file_of_sim(sim_path):\n",
    "    files = sorted(os.listdir(sim_path))\n",
    "    full_files = [os.path.join(sim_path,f) for f in files]\n",
    "    last_file = full_files[-1]\n",
    "    print(\"last file:\",last_file)\n",
    "    return last_file\n",
    "\n",
    "def return_sorted_wrf_files(directory_path):\n",
    "    matching_files = []\n",
    "    pattern = re.compile(r'\\d{4}-\\d{2}\\.nc')\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if pattern.match(filename):\n",
    "            matching_files.append(os.path.join(directory_path, filename))\n",
    "\n",
    "    return sorted(matching_files)\n",
    "\n",
    "\n",
    "#Get lat and lon indices of WRF data at closest point to target location (i.e. the site)\n",
    "ds_01 = xr.open_dataset(return_sorted_wrf_files(wrf_data)[-1],decode_times = False)\n",
    "wrf_lat_index, wrf_lon_index = getClosestWRFPoint(ds_01,target_wrf_lat,target_wrf_lon)\n",
    "\n",
    "\n",
    "print(\"Target Latitude (i.e. site latitude):\",target_wrf_lat)\n",
    "print(\"Latitude index of closest WRF point:\",wrf_lat_index)\n",
    "print(\"Latitude of closest WRF point:\",ds_01.LATIXY.sel(lat = wrf_lat_index,lon = wrf_lon_index).values)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Target Longitude (i.e. site longitude):\", target_wrf_lon)\n",
    "print(\"Longitude index of closest WRF point:\",wrf_lon_index)\n",
    "print(\"Latitude of closest WRF point:\", ds_01.LONGXY.sel(lat = wrf_lat_index,lon = wrf_lon_index).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to pre-process WRF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_all_vars_to_float32(xds):\n",
    "    vars = list(xds.keys())\n",
    "    for v in vars:\n",
    "        float_32_var = xds[v].astype(\"float32\")\n",
    "        xds[v] = float_32_var\n",
    "    return xds\n",
    "\n",
    "def change_LATIXY_and_LONGXY(xds,lat,lon):\n",
    "    LONGXY_attrs = xds.LONGXY.attrs\n",
    "    LATIXY_attrs = xds.LATIXY.attrs\n",
    "    new_LATIXY = xr.DataArray(data = np.array(lat,dtype = \"float32\").reshape(1,1),\n",
    "                              dims = ['lat','lon'],\n",
    "                              attrs = LATIXY_attrs)\n",
    "    new_LONGXY = xr.DataArray(data = np.array(lon,dtype = \"float32\").reshape(1,1),\n",
    "                              dims = ['lat','lon'],\n",
    "                              attrs = LONGXY_attrs)\n",
    "    \n",
    "    xds['LATIXY'] = new_LATIXY\n",
    "    xds['LONGXY'] = new_LONGXY\n",
    "    return xds\n",
    "\n",
    "def getRH_from_QBOT(QBOT,PSRF,TBOT):\n",
    "\n",
    "    EBOT = PSRF * QBOT / (eps_mol + (1. - eps_mol) * QBOT)\n",
    "    ESAT = esat_0C * math.exp( 17.67 * (TBOT - degC_2_K) / (TBOT - 29.65))\n",
    "    RH   = frac_2_pc * EBOT / ESAT\n",
    "    return RH\n",
    "\n",
    "    \n",
    "def put_RH_in_array(xds):\n",
    "    QBOT_array = list(xds.QBOT.values)\n",
    "    PSRF_array = list(xds.PSRF.values)\n",
    "    TBOT_array = list(xds.TBOT.values)\n",
    "    times = xds.time.values\n",
    "\n",
    "    RH_array = np.zeros(len(QBOT_array))\n",
    "    for i in range(len(QBOT_array)):\n",
    "        RH_array[i] = getRH_from_QBOT(QBOT_array[i],PSRF_array[i],TBOT_array[i])\n",
    "\n",
    "    return RH_array\n",
    "\n",
    "\n",
    "def add_RH_to_data(xds):\n",
    "    times = xds.time.values\n",
    "    n = len(times)\n",
    "    RH_array = put_RH_in_array(xds)\n",
    "\n",
    "    RH_xda = xr.DataArray(\n",
    "                 data = np.array(RH_array).reshape(n,1,1),\n",
    "                 dims = ['time','lat','lon'],\n",
    "                 coords = {\"time\": times},\n",
    "                 attrs = {\n",
    "                     'longname': 'relative humidity',\n",
    "                     'units' : '%',\n",
    "                     'mode' : 'time-dependent'\n",
    "                     })\n",
    "    xds['RH'] = RH_xda\n",
    "\n",
    "def add_ZBOT_to_data(xds):\n",
    "    times = xds.time.values\n",
    "    n = len(xds.time.values)                    \n",
    "    ZBOT_array = np.array([site_refhgt] * n).reshape(n,1,1) \n",
    "                        \n",
    "    ZBOT_xda = xr.DataArray(\n",
    "                 data = ZBOT_array.reshape(n,1,1),\n",
    "                 dims = ['time','lat','lon'],\n",
    "                 coords = {\"time\": times},\n",
    "                 attrs = {\n",
    "                     'longname': 'observation_height',\n",
    "                     'units' : 'm',\n",
    "                     'mode' : 'time-dependent'\n",
    "                     })\n",
    "    xds['ZBOT'] = ZBOT_xda\n",
    "\n",
    "    \n",
    "def add_EDGE_vars(xds):\n",
    "    \n",
    "    add = [0.5,-0.5,0.5,-0.5]\n",
    "    var = ['LATIXY','LATIXY','LONGXY','LONGXY']\n",
    "    for i,d in enumerate(['N','S','E','W']):\n",
    "        edge_var_name = \"EDGE\" + d\n",
    "        edge_value = xds[var[i]].values + add[i]\n",
    "        edge_xar = xr.DataArray(\n",
    "                     data = edge_value[0,:],\n",
    "                     dims = ['scalar'],\n",
    "                     attrs = {\n",
    "                     'longname': 'edge of datm',\n",
    "                     'units' : 'degrees',\n",
    "                     'mode' : 'time-dependent'\n",
    "                     })\n",
    "        xds[edge_var_name] = edge_xar\n",
    "\n",
    "            \n",
    "def subset_single_file(file):\n",
    "    ds = xr.open_dataset(file, decode_times = False)\n",
    "    \n",
    "    #subset\n",
    "    point_data = ds.sel(lat = slice(wrf_lat_index,(wrf_lat_index+1)),\n",
    "                        lon = slice(wrf_lon_index,(wrf_lon_index+1)))\n",
    "    \n",
    "    #get time attributes\n",
    "    time_attrs = point_data.time.attrs\n",
    "    \n",
    "    #add variables\n",
    "    add_ZBOT_to_data(point_data)\n",
    "    add_RH_to_data(point_data)\n",
    "        \n",
    "    #reset lat and lon to be same as surf data\n",
    "    point_data = change_LATIXY_and_LONGXY(cast_all_vars_to_float32(point_data),target_lat,target_lon)\n",
    "    \n",
    "    #add edge values\n",
    "    add_EDGE_vars(point_data)\n",
    "    \n",
    "    #re-assign time attributes to data\n",
    "    point_data.time.attrs = time_attrs\n",
    "    \n",
    "    #write output\n",
    "    new_file_name = output_path + \"/\" + os.path.basename(file)\n",
    "    point_data.to_netcdf(new_file_name, format = \"NETCDF3_64BIT\", mode = \"w\")\n",
    "    ds.close()\n",
    "    point_data.close()\n",
    "    print(\"Finished\",new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pre-processing functions to WRF domain files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(wrf_data + \"/*1980*.nc\")\n",
    "files = return_sorted_wrf_files(wrf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(files):\n",
    "    subset_single_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4_work",
   "language": "python",
   "name": "env4_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
